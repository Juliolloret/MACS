import json

class FakeLLM:
    def __init__(self, app_config=None, response_map=None):
        self.app_config = app_config
        self.client = self
        self.response_map = response_map or {}

    def get_response(self, system_message, user_message, model, temperature):
        if user_message in self.response_map:
            return self.response_map[user_message]
        if "generate hypotheses" in user_message.lower() or "propose" in user_message.lower():
            return json.dumps({
                "key_opportunities": "This is a fake opportunity generated for testing by FakeLLM.",
                "hypotheses": [
                    {
                        "hypothesis": "This is a fake test hypothesis generated by FakeLLM.",
                        "justification": "This hypothesis is designed for testing the application."
                    }
                ]
            })
        return f"[FAKE] ok"

    def complete(self, system, prompt, model, temperature=0.1):
        # The user message is the prompt in the complete method
        return self.get_response(system, prompt, model, temperature)

    def embeddings(self, input, model):
        # Return a dummy embedding
        return self

    def create(self, input, model):
        # Return a dummy embedding
        return self

    @property
    def data(self):
        return [self]

    @property
    def embedding(self):
        return [[0.1, 0.2, 0.3]]
